#!/usr/bin/env python3
"""
Join Direct and Supervision Data Script

This script reads separate direct and supervision service data files,
calculates overlaps between them, and produces the same output format
that was previously generated by the complex SQL query.

Usage:
    python join_supervision_data.py [--direct-input PATH] [--supervision-input PATH] [--output PATH]
"""

import pandas as pd
import os
import logging
import argparse
from datetime import datetime
from typing import Tuple


def setup_logging(log_dir: str = None) -> logging.Logger:
    """Set up logging configuration."""
    # Use root logs directory if not specified
    if log_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # Go up from scripts_notebooks/prod to project root
        project_root = os.path.dirname(os.path.dirname(script_dir))
        log_dir = os.path.join(project_root, 'logs')
    
    # Ensure logs directory exists
    os.makedirs(log_dir, exist_ok=True)
    
    # Create log file path
    log_file = os.path.join(log_dir, 'join_supervision_data.log')
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)


def calculate_overlap_hours(d_start: pd.Timestamp, d_end: pd.Timestamp,
                            s_start: pd.Timestamp, s_end: pd.Timestamp) -> float:
    """
    Calculate overlap hours between two time ranges.
    
    Args:
        d_start, d_end: Direct service time range
        s_start, s_end: Supervision service time range
        
    Returns:
        float: Overlap hours
    """
    # Check if there's any overlap
    if d_start >= s_end or d_end <= s_start:
        return 0.0
    
    # Calculate overlap
    overlap_start = max(d_start, s_start)
    overlap_end = min(d_end, s_end)
    overlap_minutes = (overlap_end - overlap_start).total_seconds() / 60.0
    return overlap_minutes / 60.0


def filter_bcbas(df: pd.DataFrame, logger: logging.Logger) -> pd.DataFrame:
    """
    Filter out BCBAs from direct provider data.
    BCBA filtering is now handled in the SQL query, so this function
    is kept for compatibility but doesn't do anything.
    
    Args:
        df: DataFrame with ProviderContactId
        logger: Logger instance
        
    Returns:
        pd.DataFrame: DataFrame (unchanged, filtering done in SQL)
    """
    # BCBA filtering is now handled in the SQL query
    return df


def join_supervision_data(direct_df: pd.DataFrame, supervision_df: pd.DataFrame,
                          logger: logging.Logger) -> pd.DataFrame:
    """
    Join direct and supervision data, calculating overlaps and producing
    the same output format as the original SQL query.
    
    Args:
        direct_df: Direct services DataFrame
        supervision_df: Supervision services DataFrame
        logger: Logger instance
        
    Returns:
        pd.DataFrame: Joined data with same structure as original SQL output
    """
    logger.info("="*50)
    logger.info("Joining Direct and Supervision Data")
    logger.info("="*50)
    logger.info(f"Direct services: {len(direct_df)} rows")
    logger.info(f"Supervision services: {len(supervision_df)} rows")
    
    # Convert time columns to datetime if they're not already
    for df in [direct_df, supervision_df]:
        if 'ServiceStartTime' in df.columns:
            df['ServiceStartTime'] = pd.to_datetime(df['ServiceStartTime'])
        if 'ServiceEndTime' in df.columns:
            df['ServiceEndTime'] = pd.to_datetime(df['ServiceEndTime'])
    
    # Filter BCBAs from direct data (if we have employee data)
    # For now, we'll proceed without filtering
    direct_df = filter_bcbas(direct_df, logger)
    
    # Step 1: Calculate duration for each entry first
    logger.info("Calculating entry durations...")
    direct_df['DurationHours'] = (
        (direct_df['ServiceEndTime'] - direct_df['ServiceStartTime']).dt.total_seconds() / 3600.0
    )
    supervision_df['DurationHours'] = (
        (supervision_df['ServiceEndTime'] - supervision_df['ServiceStartTime']).dt.total_seconds() / 3600.0
    )
    
    # Step 2: Calculate overlaps between direct and supervision entries (must be at entry level for time matching)
    logger.info("Calculating overlaps between direct and supervision entries...")
    overlap_rows = []
    
    # Group by client for efficiency
    for client_id in direct_df['ClientContactId'].unique():
        client_direct = direct_df[direct_df['ClientContactId'] == client_id].copy()
        client_supervision = supervision_df[supervision_df['ClientContactId'] == client_id].copy()
        
        if len(client_supervision) == 0:
            continue
        
        # Check each direct entry against each supervision entry
        for _, d_row in client_direct.iterrows():
            for _, s_row in client_supervision.iterrows():
                overlap_hours = calculate_overlap_hours(
                    d_row['ServiceStartTime'], d_row['ServiceEndTime'],
                    s_row['ServiceStartTime'], s_row['ServiceEndTime']
                )
                
                if overlap_hours > 0:
                    overlap_rows.append({
                        'ClientContactId': client_id,
                        'ClientFullName': d_row['ClientFullName'],
                        'ClientOfficeLocationName': d_row['ClientOfficeLocationName'],
                        'DirectProviderId': d_row['ProviderContactId'],
                        'SupervisorProviderId': s_row['ProviderContactId'],
                        'DirectServiceLocationName': d_row['ServiceLocationName'],
                        'SupervisorServiceLocationName': s_row['ServiceLocationName'],
                        'OverlapHours': overlap_hours
                    })
    
    # Step 3: Aggregate overlaps by client, provider, supervisor, and locations
    if overlap_rows:
        overlap_df = pd.DataFrame(overlap_rows)
        logger.info(f"Found {len(overlap_df)} overlap entries")
        overlap_agg = overlap_df.groupby([
            'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
            'DirectProviderId', 'SupervisorProviderId',
            'DirectServiceLocationName', 'SupervisorServiceLocationName'
        ]).agg({
            'OverlapHours': 'sum'
        }).reset_index()
        logger.info(f"Aggregated to {len(overlap_agg)} unique overlap combinations")
    else:
        overlap_agg = pd.DataFrame(columns=[
            'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
            'DirectProviderId', 'SupervisorProviderId',
            'DirectServiceLocationName', 'SupervisorServiceLocationName', 'OverlapHours'
        ])
        logger.info("No overlaps found")
    
    # Step 4: Calculate total direct hours per client, provider, and location
    logger.info("Calculating total direct hours...")
    direct_totals = direct_df.groupby([
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'ProviderContactId', 'ServiceLocationName'
    ]).agg({
        'DurationHours': 'sum'
    }).reset_index()
    direct_totals.columns = [
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'ProviderContactId', 'ServiceLocationName', 'DirectHours_Total'
    ]
    logger.info(f"Calculated direct totals for {len(direct_totals)} client/provider/location combinations")
    
    # Step 5: Calculate total overlap hours per client, direct provider, and location
    if len(overlap_agg) > 0:
        overlap_by_direct = overlap_agg.groupby([
            'ClientContactId', 'DirectProviderId', 'DirectServiceLocationName'
        ]).agg({
            'OverlapHours': 'sum'
        }).reset_index()
        overlap_by_direct.columns = ['ClientContactId', 'DirectProviderId', 'DirectServiceLocationName', 'OverlapHours_Total']
    else:
        overlap_by_direct = pd.DataFrame(columns=[
            'ClientContactId', 'DirectProviderId', 'DirectServiceLocationName', 'OverlapHours_Total'
        ])
    
    # Step 6: Calculate direct-only hours (total direct minus overlapped)
    direct_only = direct_totals.merge(
        overlap_by_direct,
        left_on=['ClientContactId', 'ProviderContactId', 'ServiceLocationName'],
        right_on=['ClientContactId', 'DirectProviderId', 'DirectServiceLocationName'],
        how='left'
    )
    direct_only['OverlapHours_Total'] = direct_only['OverlapHours_Total'].fillna(0.0)
    direct_only['DirectHours_NoSupervision'] = (
        direct_only['DirectHours_Total'] - direct_only['OverlapHours_Total']
    )
    direct_only = direct_only[direct_only['DirectHours_NoSupervision'] > 0].copy()
    direct_only = direct_only[[
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'ProviderContactId', 'ServiceLocationName', 'DirectHours_NoSupervision'
    ]]
    direct_only.columns = [
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'DirectProviderId', 'DirectServiceLocationName', 'DirectHours_NoSupervision'
    ]
    logger.info(f"Direct-only entries: {len(direct_only)}")
    
    # Step 7: Calculate total supervision hours per client, supervisor, and location
    logger.info("Calculating total supervision hours...")
    supervision_totals = supervision_df.groupby([
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'ProviderContactId', 'ServiceLocationName'
    ]).agg({
        'DurationHours': 'sum'
    }).reset_index()
    supervision_totals.columns = [
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'SupervisorProviderId', 'SupervisorServiceLocationName', 'SupervisionHours_Total'
    ]
    logger.info(f"Calculated supervision totals for {len(supervision_totals)} client/supervisor/location combinations")
    
    # Step 8: Calculate overlap hours per supervisor/location
    if len(overlap_agg) > 0:
        overlap_by_supervision = overlap_agg.groupby([
            'ClientContactId', 'SupervisorProviderId', 'SupervisorServiceLocationName'
        ]).agg({
            'OverlapHours': 'sum'
        }).reset_index()
        overlap_by_supervision.columns = [
            'ClientContactId', 'SupervisorProviderId', 'SupervisorServiceLocationName', 'OverlapHours_Total'
        ]
    else:
        overlap_by_supervision = pd.DataFrame(columns=[
            'ClientContactId', 'SupervisorProviderId', 'SupervisorServiceLocationName', 'OverlapHours_Total'
        ])
    
    # Step 9: Calculate supervision-only hours (total supervision minus overlapped)
    supervision_only = supervision_totals.merge(
        overlap_by_supervision,
        on=['ClientContactId', 'SupervisorProviderId', 'SupervisorServiceLocationName'],
        how='left'
    )
    supervision_only['OverlapHours_Total'] = supervision_only['OverlapHours_Total'].fillna(0.0)
    supervision_only['SupervisionHours_NoDirect'] = (
        supervision_only['SupervisionHours_Total'] - supervision_only['OverlapHours_Total']
    )
    supervision_only = supervision_only[supervision_only['SupervisionHours_NoDirect'] > 0].copy()
    supervision_only = supervision_only[[
        'ClientContactId', 'ClientFullName', 'ClientOfficeLocationName',
        'SupervisorProviderId', 'SupervisorServiceLocationName', 'SupervisionHours_NoDirect'
    ]]
    logger.info(f"Supervision-only entries: {len(supervision_only)}")
    
    # Step 10: Get provider names from the original dataframes (create maps once)
    logger.info("Creating provider name maps...")
    direct_name_map = {}
    if 'ProviderFirstName' in direct_df.columns and 'ProviderLastName' in direct_df.columns:
        # Use groupby to get unique provider names (more efficient)
        provider_names = direct_df.groupby('ProviderContactId').agg({
            'ProviderFirstName': 'first',
            'ProviderLastName': 'first'
        }).reset_index()
        for _, row in provider_names.iterrows():
            if pd.notna(row['ProviderContactId']):
                direct_name_map[row['ProviderContactId']] = (
                    row['ProviderFirstName'], row['ProviderLastName']
                )
    
    supervision_name_map = {}
    if 'ProviderFirstName' in supervision_df.columns and 'ProviderLastName' in supervision_df.columns:
        # Use groupby to get unique provider names (more efficient)
        supervisor_names = supervision_df.groupby('ProviderContactId').agg({
            'ProviderFirstName': 'first',
            'ProviderLastName': 'first'
        }).reset_index()
        for _, row in supervisor_names.iterrows():
            if pd.notna(row['ProviderContactId']):
                supervision_name_map[row['ProviderContactId']] = (
                    row['ProviderFirstName'], row['ProviderLastName']
                )
    
    # Step 11: Aggregate overlaps by provider/location (not per client) to reduce rows
    # The transform step will aggregate by provider/clinic anyway, so we can do it here
    logger.info("Aggregating overlaps by provider and location (across all clients)...")
    if len(overlap_agg) > 0:
        # Get first client info for each provider/location combo (for output format)
        overlap_by_provider = overlap_agg.groupby([
            'DirectProviderId', 'SupervisorProviderId',
            'DirectServiceLocationName', 'SupervisorServiceLocationName',
            'ClientOfficeLocationName'  # Keep for clinic name extraction
        ]).agg({
            'OverlapHours': 'sum',
            'ClientContactId': 'first',  # Keep first for output format
            'ClientFullName': 'first'    # Keep first for output format
        }).reset_index()
        logger.info(f"Aggregated overlaps to {len(overlap_by_provider)} provider/location combinations")
    else:
        overlap_by_provider = pd.DataFrame(columns=[
            'DirectProviderId', 'SupervisorProviderId',
            'DirectServiceLocationName', 'SupervisorServiceLocationName',
            'ClientOfficeLocationName', 'OverlapHours', 'ClientContactId', 'ClientFullName'
        ])
    
    # Step 12: Aggregate direct-only by provider/location (across all clients)
    logger.info("Aggregating direct-only by provider and location (across all clients)...")
    if len(direct_only) > 0:
        direct_only_agg = direct_only.groupby([
            'DirectProviderId', 'DirectServiceLocationName', 'ClientOfficeLocationName'
        ]).agg({
            'DirectHours_NoSupervision': 'sum',
            'ClientContactId': 'first',
            'ClientFullName': 'first'
        }).reset_index()
        logger.info(f"Aggregated direct-only to {len(direct_only_agg)} provider/location combinations")
    else:
        direct_only_agg = pd.DataFrame(columns=[
            'DirectProviderId', 'DirectServiceLocationName', 'ClientOfficeLocationName',
            'DirectHours_NoSupervision', 'ClientContactId', 'ClientFullName'
        ])
    
    # Step 13: Create named_direct_only rows (from aggregated data)
    named_direct_only_rows = []
    for _, row in direct_only_agg.iterrows():
        provider_id = row['DirectProviderId']
        first_name, last_name = direct_name_map.get(provider_id, (None, None))
        named_direct_only_rows.append({
            'ClientContactId': row['ClientContactId'],
            'ClientFullName': row['ClientFullName'],
            'ClientOfficeLocationName': row['ClientOfficeLocationName'],
            'DirectProviderId': provider_id,
            'DirectFirstName': first_name,
            'DirectLastName': last_name,
            'DirectServiceLocationName': row['DirectServiceLocationName'],
            'DirectHours': round(row['DirectHours_NoSupervision'], 2),
            'SupervisionHours': 0.0,
            'SupervisorFirstName': None,
            'SupervisorLastName': None,
            'SupervisorServiceLocationName': None,
            'RowType': 'Direct (no supervision overlap)'
        })
    
    # Step 14: Create named_overlap rows (from aggregated data)
    named_overlap_rows = []
    if len(overlap_by_provider) > 0:
        for _, row in overlap_by_provider.iterrows():
            direct_id = row['DirectProviderId']
            supervisor_id = row['SupervisorProviderId']
            direct_first, direct_last = direct_name_map.get(direct_id, (None, None))
            sup_first, sup_last = supervision_name_map.get(supervisor_id, (None, None))
            named_overlap_rows.append({
                'ClientContactId': row['ClientContactId'],
                'ClientFullName': row['ClientFullName'],
                'ClientOfficeLocationName': row['ClientOfficeLocationName'],
                'DirectProviderId': direct_id,
                'DirectFirstName': direct_first,
                'DirectLastName': direct_last,
                'DirectServiceLocationName': row['DirectServiceLocationName'],
                'DirectHours': round(row['OverlapHours'], 2),
                'SupervisionHours': round(row['OverlapHours'], 2),
                'SupervisorFirstName': sup_first,
                'SupervisorLastName': sup_last,
                'SupervisorServiceLocationName': row['SupervisorServiceLocationName'],
                'RowType': 'Direct overlapped with supervision'
            })
    
    # Step 15: Create named_supervision_only rows (aggregate first)
    logger.info("Aggregating supervision-only by provider and location (across all clients)...")
    if len(supervision_only) > 0:
        supervision_only_agg = supervision_only.groupby([
            'SupervisorProviderId', 'SupervisorServiceLocationName', 'ClientOfficeLocationName'
        ]).agg({
            'SupervisionHours_NoDirect': 'sum',
            'ClientContactId': 'first',
            'ClientFullName': 'first'
        }).reset_index()
        logger.info(f"Aggregated supervision-only to {len(supervision_only_agg)} provider/location combinations")
    else:
        supervision_only_agg = pd.DataFrame(columns=[
            'SupervisorProviderId', 'SupervisorServiceLocationName', 'ClientOfficeLocationName',
            'SupervisionHours_NoDirect', 'ClientContactId', 'ClientFullName'
        ])
    
    named_supervision_only_rows = []
    for _, row in supervision_only_agg.iterrows():
        supervisor_id = row['SupervisorProviderId']
        sup_first, sup_last = supervision_name_map.get(supervisor_id, (None, None))
        named_supervision_only_rows.append({
            'ClientContactId': row['ClientContactId'],
            'ClientFullName': row['ClientFullName'],
            'ClientOfficeLocationName': row['ClientOfficeLocationName'],
            'DirectProviderId': None,
            'DirectFirstName': None,
            'DirectLastName': None,
            'DirectServiceLocationName': None,
            'DirectHours': 0.0,
            'SupervisionHours': round(row['SupervisionHours_NoDirect'], 2),
            'SupervisorFirstName': sup_first,
            'SupervisorLastName': sup_last,
            'SupervisorServiceLocationName': row['SupervisorServiceLocationName'],
            'RowType': 'Supervision without direct overlap'
        })
    
    # Step 16: Combine all rows
    all_rows = named_direct_only_rows + named_overlap_rows + named_supervision_only_rows
    result_df = pd.DataFrame(all_rows)
    
    # Filter out rows with zero hours
    result_df = result_df[
        (result_df['DirectHours'] > 0) | (result_df['SupervisionHours'] > 0)
    ].copy()
    
    # Sort
    result_df = result_df.sort_values(by=[
        'ClientFullName', 'DirectLastName', 'DirectFirstName',
        'SupervisorLastName', 'SupervisorFirstName',
        'DirectServiceLocationName', 'SupervisorServiceLocationName'
    ])
    
    logger.info(f"Final joined dataset: {len(result_df)} rows")
    logger.info(f"  - Direct only: {len(named_direct_only_rows)}")
    logger.info(f"  - Overlap: {len(named_overlap_rows)}")
    logger.info(f"  - Supervision only: {len(named_supervision_only_rows)}")
    
    return result_df




def join_supervision_data_main(direct_df: pd.DataFrame = None, supervision_df: pd.DataFrame = None,
                               direct_file: str = None, supervision_file: str = None,
                               save_file: bool = True) -> pd.DataFrame:
    """
    Main function to join direct and supervision data.
    
    Args:
        direct_df (pd.DataFrame, optional): Direct services DataFrame. If None, will read from direct_file.
        supervision_df (pd.DataFrame, optional): Supervision services DataFrame. If None, will read from supervision_file.
        direct_file (str, optional): Direct services CSV file path. Used if direct_df is None.
        supervision_file (str, optional): Supervision services CSV file path. Used if supervision_df is None.
        save_file (bool): Whether to save file to disk. Default True.
        
    Returns:
        pd.DataFrame: Joined DataFrame
    """
    # Set up logging
    logger = setup_logging()
    
    # Get direct data
    if direct_df is None:
        if direct_file is None:
            today = datetime.now().strftime('%Y-%m-%d')
            direct_file = f'../../data/raw_pulls/direct_services_{today}.csv'
        
        if not os.path.exists(direct_file):
            logger.error(f"Direct services file not found: {direct_file}")
            raise FileNotFoundError(f"Direct services file not found: {direct_file}")
        
        logger.info(f"Reading direct services from: {direct_file}")
        direct_df = pd.read_csv(direct_file)
        logger.info(f"Loaded {len(direct_df)} rows from direct services file")
    else:
        logger.info(f"Using provided direct DataFrame with {len(direct_df)} rows")
    
    # Get supervision data
    if supervision_df is None:
        if supervision_file is None:
            today = datetime.now().strftime('%Y-%m-%d')
            supervision_file = f'../../data/raw_pulls/supervision_services_{today}.csv'
        
        if not os.path.exists(supervision_file):
            logger.error(f"Supervision services file not found: {supervision_file}")
            raise FileNotFoundError(f"Supervision services file not found: {supervision_file}")
        
        logger.info(f"Reading supervision services from: {supervision_file}")
        supervision_df = pd.read_csv(supervision_file)
        logger.info(f"Loaded {len(supervision_df)} rows from supervision services file")
    else:
        logger.info(f"Using provided supervision DataFrame with {len(supervision_df)} rows")
    
    # Join data
    joined_df = join_supervision_data(direct_df, supervision_df, logger)
    
    if save_file:
        # Save joined data
        today = datetime.now().strftime('%Y-%m-%d')
        output_file = f'../../data/raw_pulls/daily_supervision_hours_{today}.csv'
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        joined_df.to_csv(output_file, index=False)
        logger.info(f"Saved joined data to: {output_file}")
    
    logger.info("="*50)
    logger.info("Data join completed successfully!")
    logger.info("="*50)
    
    return joined_df


def main():
    """CLI entry point for join_supervision_data.py"""
    parser = argparse.ArgumentParser(description='Join direct and supervision service data')
    parser.add_argument('--direct-input', type=str,
                       default='../../data/raw_pulls/direct_services_{date}.csv',
                       help='Input CSV file path for direct services (use {date} placeholder)')
    parser.add_argument('--supervision-input', type=str,
                       default='../../data/raw_pulls/supervision_services_{date}.csv',
                       help='Input CSV file path for supervision services (use {date} placeholder)')
    parser.add_argument('--output', type=str,
                       default='../../data/raw_pulls/daily_supervision_hours_{date}.csv',
                       help='Output CSV file path (use {date} placeholder)')
    
    args = parser.parse_args()
    
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        direct_file = args.direct_input.format(date=today)
        supervision_file = args.supervision_input.format(date=today)
        join_supervision_data_main(direct_file=direct_file, supervision_file=supervision_file, save_file=True)
        return 0
    except Exception as e:
        logging.error(f"Error in data join: {e}")
        raise


if __name__ == "__main__":
    exit(main())

